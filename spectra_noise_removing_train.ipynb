{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spectra_noise removing train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsbA22kSrEdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d55e795-2ecc-4601-d871-e9fd1fd5b885"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from astropy.io import fits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "from itertools import permutations\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "import pickle\n",
        "\n",
        "from keras import Model\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout, LeakyReLU\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: AstropyDeprecationWarning: block_reduce was moved to the astropy.nddata.blocks module.  Please update your import statement. [astropy.nddata.utils]\n",
            "WARNING: AstropyDeprecationWarning: block_replicate was moved to the astropy.nddata.blocks module.  Please update your import statement. [astropy.nddata.utils]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMRVYb52sdxp"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QCabNQQrqF2"
      },
      "source": [
        "def build_model(size, start_neurons=8):\n",
        "    input_layer = Input(size + (1,))\n",
        "    \n",
        "    conv1 = Conv2D(start_neurons*1,(3,3), padding=\"same\")(input_layer)\n",
        "    conv1 = LeakyReLU(alpha=0.1)(conv1)\n",
        "    conv1 = Conv2D(start_neurons*1,(3,3), padding=\"same\")(conv1)\n",
        "    conv1 = LeakyReLU(alpha=0.1)(conv1)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "    pool1 = Dropout(0.25)(pool1)\n",
        "\n",
        "    conv2 = Conv2D(start_neurons*2,(3,3), padding=\"same\")(pool1)\n",
        "    conv2 = LeakyReLU(alpha=0.1)(conv2)\n",
        "    conv2 = Conv2D(start_neurons*2,(3,3), padding=\"same\")(conv2)\n",
        "    conv2 = LeakyReLU(alpha=0.1)(conv2)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "    pool2 = Dropout(0.5)(pool2)\n",
        "\n",
        "    conv3 = Conv2D(start_neurons*4,(3,3), padding=\"same\")(pool2)\n",
        "    conv3 = LeakyReLU(alpha=0.1)(conv3)\n",
        "    conv3 = Conv2D(start_neurons*4,(3,3), padding=\"same\")(conv3)\n",
        "    conv3 = LeakyReLU(alpha=0.1)(conv3)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "    pool3 = Dropout(0.5)(pool3)\n",
        "\n",
        "    conv4 = Conv2D(start_neurons*8,(3,3), padding=\"same\")(pool3)\n",
        "    conv4 = LeakyReLU(alpha=0.1)(conv4)\n",
        "    conv4 = Conv2D(start_neurons*8,(3,3), padding=\"same\")(conv4)\n",
        "    conv4 = LeakyReLU(alpha=0.1)(conv4)\n",
        "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
        "    pool4 = Dropout(0.5)(pool4)\n",
        "\n",
        "    conv5 = Conv2D(start_neurons*16,(3,3), padding=\"same\")(pool4)\n",
        "    conv5 = LeakyReLU(alpha=0.1)(conv5)\n",
        "    conv5 = Conv2D(start_neurons*16,(3,3), padding=\"same\")(conv5)\n",
        "    conv5 = LeakyReLU(alpha=0.1)(conv5)\n",
        "    pool5 = MaxPooling2D((2, 2))(conv5)\n",
        "    pool5 = Dropout(0.5)(pool5)\n",
        "\n",
        "    # Middle\n",
        "    convm = Conv2D(start_neurons*32,(3,3), padding=\"same\")(pool5)\n",
        "    convm = LeakyReLU(alpha=0.1)(convm)\n",
        "    convm = Conv2D(start_neurons*32,(3,3), padding=\"same\")(convm)\n",
        "    convm = LeakyReLU(alpha=0.1)(convm)\n",
        "\n",
        "    deconv5 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
        "    uconv5 = concatenate([deconv5, conv5])\n",
        "    uconv5 = Dropout(0.5)(uconv5)\n",
        "    uconv5 = Conv2D(start_neurons*16,(3,3), padding=\"same\")(uconv5)\n",
        "    uconv5 = LeakyReLU(alpha=0.1)(uconv5)\n",
        "    uconv5 = Conv2D(start_neurons*16,(3,3), padding=\"same\")(uconv5)\n",
        "    uconv5 = LeakyReLU(alpha=0.1)(uconv5)\n",
        "\n",
        "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv5)\n",
        "    uconv4 = concatenate([deconv4, conv4])\n",
        "    uconv4 = Dropout(0.5)(uconv4)\n",
        "    uconv4 = Conv2D(start_neurons*8,(3,3), padding=\"same\")(uconv4)\n",
        "    uconv4 = LeakyReLU(alpha=0.1)(uconv4)\n",
        "    uconv4 = Conv2D(start_neurons*8,(3,3), padding=\"same\")(uconv4)\n",
        "    uconv4 = LeakyReLU(alpha=0.1)(uconv4)\n",
        "\n",
        "    deconv3 = Conv2DTranspose(start_neurons*4,(3,3),strides=(2, 2), padding=\"same\")(uconv4)\n",
        "    uconv3 = concatenate([deconv3, conv3])\n",
        "    uconv3 = Dropout(0.5)(uconv3)\n",
        "    uconv3 = Conv2D(start_neurons*4,(3,3), padding=\"same\")(uconv3)\n",
        "    uconv3 = LeakyReLU(alpha=0.1)(uconv3)\n",
        "    uconv3 = Conv2D(start_neurons*4,(3,3), padding=\"same\")(uconv3)\n",
        "    uconv3 = LeakyReLU(alpha=0.1)(uconv3)\n",
        "\n",
        "    deconv2 = Conv2DTranspose(start_neurons*2,(3,3),strides=(2, 2), padding=\"same\")(uconv3)\n",
        "    uconv2 = concatenate([deconv2, conv2])\n",
        "    uconv2 = Dropout(0.5)(uconv2)\n",
        "    uconv2 = Conv2D(start_neurons*2,(3,3), padding=\"same\")(uconv2)\n",
        "    uconv2 = LeakyReLU(alpha=0.1)(uconv2)\n",
        "    uconv2 = Conv2D(start_neurons*2,(3,3), padding=\"same\")(uconv2)\n",
        "    uconv2 = LeakyReLU(alpha=0.1)(uconv2)\n",
        "\n",
        "    deconv1 = Conv2DTranspose(start_neurons*1,(3,3),strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    uconv1 = concatenate([deconv1, conv1])\n",
        "    uconv1 = Dropout(0.5)(uconv1)\n",
        "    uconv1 = Conv2D(start_neurons*1,(3,3), padding=\"same\")(uconv1)\n",
        "    uconv1 = LeakyReLU(alpha=0.1)(uconv1)\n",
        "    uconv1 = Conv2D(start_neurons*1,(3,3), padding=\"same\")(uconv1)\n",
        "    uconv1 = LeakyReLU(alpha=0.1)(uconv1)\n",
        "\n",
        "    uncov1 = Dropout(0.5)(uconv1)\n",
        "    output_layer = Conv2D(1,(1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
        "    \n",
        "    model = Model(input_layer, output_layer)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuzu6IHwwcqa"
      },
      "source": [
        "def PSNR(y_true, y_pred):\n",
        "    max_pixel = 255\n",
        "    return 10.0 * K.log((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true))))/K.log(10.0)\n",
        "\n",
        "get_custom_objects().update({'PSNR': PSNR})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBxbw8qbcuUr"
      },
      "source": [
        "def SSIM(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
        "\n",
        "get_custom_objects().update({'SSIM': SSIM})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn_qK8HqwVib"
      },
      "source": [
        "def MSE(img1, img2):\n",
        "    shape = np.array(img1.shape).prod()\n",
        "    res = ((img1-img2)**2).sum()/shape\n",
        "    if (res == 0):\n",
        "        raise ValueError\n",
        "    else:\n",
        "        return res\n",
        "\n",
        "def compute_psnr(img_pred, img_gt):\n",
        "    img_pred = img_pred.astype('float64')\n",
        "    img_gt = img_gt.astype('float64')\n",
        "    max_pixel = 255\n",
        "    return 10*np.log10(max_pixel**2/MSE(img_pred, img_gt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs9E7VDHstas"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YskrLRhslQe"
      },
      "source": [
        "data_dir = 'drive/MyDrive/CV/Coursework/images'\n",
        "dirs = listdir(data_dir)\n",
        "\n",
        "combinations = []\n",
        "\n",
        "for dir in dirs:\n",
        "  cur_dir = join(data_dir, dir)\n",
        "  files = listdir(cur_dir)\n",
        "\n",
        "  for i,file in enumerate(files):\n",
        "    files[i] = join(cur_dir, file)\n",
        "\n",
        "  combinations.extend(list(permutations(files, 2)))\n",
        "\n",
        "train, valid = train_test_split(combinations, test_size=0.1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcHIkAwiIF9d"
      },
      "source": [
        "def datagen(pairs, size, batch_size):\n",
        "    x = np.empty((batch_size,)+size)\n",
        "    y = np.empty((batch_size,)+size)\n",
        "\n",
        "    batch_ind = 0\n",
        "    epoch_ind = 0\n",
        "    n_samples = len(pairs)\n",
        "\n",
        "    while True:\n",
        "        train_img = imread(pairs[epoch_ind][0], as_gray=True)\n",
        "        target_img = imread(pairs[epoch_ind][1], as_gray=True)\n",
        "\n",
        "        x[batch_ind] = resize(train_img, size)\n",
        "        y[batch_ind] = resize(target_img, size)\n",
        "\n",
        "        batch_ind += 1\n",
        "        epoch_ind += 1\n",
        "\n",
        "        if batch_ind == batch_size:\n",
        "            batch_ind = 0\n",
        "            yield x.reshape(x.shape+(1,)), y.reshape(y.shape+(1,))\n",
        "\n",
        "        if epoch_ind == n_samples:\n",
        "            epoch_ind = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b_gGxvkMYzq"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tURtQUl5MaDR",
        "outputId": "a4aff07e-7d27-4437-b49c-68b777077eaf"
      },
      "source": [
        "size = (256,1024)\n",
        "batch_size = 16\n",
        "epochs = 30\n",
        "\n",
        "train_datagen = datagen(train, size, batch_size)\n",
        "valid_datagen = datagen(valid, size, batch_size)\n",
        "\n",
        "steps_per_train_epoch = len(train)//batch_size\n",
        "steps_per_valid_epoch = len(valid)//batch_size\n",
        "\n",
        "model = build_model(size)\n",
        "\n",
        "model.compile(loss='mse', optimizer=Adam(), metrics=['PSNR', 'SSIM'])\n",
        "\n",
        "history = model.fit(train_datagen, \n",
        "                    epochs=epochs, \n",
        "                    batch_size=batch_size, \n",
        "                    verbose=1,\n",
        "                    validation_data=valid_datagen,\n",
        "                    steps_per_epoch=steps_per_train_epoch,\n",
        "                    validation_steps=steps_per_valid_epoch\n",
        "                    )\n",
        "\n",
        "model_name = 'cr_removing'\n",
        "model_dir = 'drive/MyDrive/CV/Coursework/models'\n",
        "stats_dir = 'drive/MyDrive/CV/Coursework/models'\n",
        "\n",
        "model.save(join(model_dir, 'model_{}.hdf5'.format(model_name)))\n",
        "with open(join(stats_dir, 'stats_{}.pickle'.format(model_name)), 'wb') as f:\n",
        "    pickle.dump(history.history, f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "164/164 [==============================] - 1894s 12s/step - loss: 0.0381 - PSNR: 62.9484 - SSIM: 0.3252 - val_loss: 0.0188 - val_PSNR: 65.5916 - val_SSIM: 0.5204\n",
            "Epoch 2/30\n",
            "164/164 [==============================] - 960s 6s/step - loss: 0.0191 - PSNR: 65.6294 - SSIM: 0.4832 - val_loss: 0.0162 - val_PSNR: 66.3843 - val_SSIM: 0.5609\n",
            "Epoch 3/30\n",
            "164/164 [==============================] - 939s 6s/step - loss: 0.0182 - PSNR: 65.8910 - SSIM: 0.5007 - val_loss: 0.0159 - val_PSNR: 66.3565 - val_SSIM: 0.5659\n",
            "Epoch 4/30\n",
            "164/164 [==============================] - 929s 6s/step - loss: 0.0178 - PSNR: 65.9584 - SSIM: 0.5090 - val_loss: 0.0157 - val_PSNR: 66.5073 - val_SSIM: 0.5698\n",
            "Epoch 5/30\n",
            "164/164 [==============================] - 933s 6s/step - loss: 0.0177 - PSNR: 66.0196 - SSIM: 0.5140 - val_loss: 0.0152 - val_PSNR: 66.6971 - val_SSIM: 0.5730\n",
            "Epoch 6/30\n",
            "164/164 [==============================] - 941s 6s/step - loss: 0.0175 - PSNR: 66.0709 - SSIM: 0.5185 - val_loss: 0.0153 - val_PSNR: 66.6309 - val_SSIM: 0.5764\n",
            "Epoch 7/30\n",
            "164/164 [==============================] - 940s 6s/step - loss: 0.0173 - PSNR: 66.1084 - SSIM: 0.5222 - val_loss: 0.0152 - val_PSNR: 66.6539 - val_SSIM: 0.5787\n",
            "Epoch 8/30\n",
            "164/164 [==============================] - 936s 6s/step - loss: 0.0173 - PSNR: 66.1545 - SSIM: 0.5254 - val_loss: 0.0152 - val_PSNR: 66.6109 - val_SSIM: 0.5718\n",
            "Epoch 9/30\n",
            "164/164 [==============================] - 932s 6s/step - loss: 0.0169 - PSNR: 66.2305 - SSIM: 0.5289 - val_loss: 0.0144 - val_PSNR: 66.9076 - val_SSIM: 0.5765\n",
            "Epoch 10/30\n",
            "164/164 [==============================] - 933s 6s/step - loss: 0.0171 - PSNR: 66.1942 - SSIM: 0.5310 - val_loss: 0.0147 - val_PSNR: 66.8068 - val_SSIM: 0.5806\n",
            "Epoch 11/30\n",
            "164/164 [==============================] - 933s 6s/step - loss: 0.0167 - PSNR: 66.2723 - SSIM: 0.5337 - val_loss: 0.0146 - val_PSNR: 66.7773 - val_SSIM: 0.5778\n",
            "Epoch 12/30\n",
            "164/164 [==============================] - 934s 6s/step - loss: 0.0165 - PSNR: 66.3525 - SSIM: 0.5345 - val_loss: 0.0144 - val_PSNR: 66.8355 - val_SSIM: 0.5839\n",
            "Epoch 13/30\n",
            "164/164 [==============================] - 936s 6s/step - loss: 0.0163 - PSNR: 66.3785 - SSIM: 0.5367 - val_loss: 0.0141 - val_PSNR: 66.9864 - val_SSIM: 0.5767\n",
            "Epoch 14/30\n",
            "164/164 [==============================] - 929s 6s/step - loss: 0.0161 - PSNR: 66.4128 - SSIM: 0.5389 - val_loss: 0.0143 - val_PSNR: 66.8583 - val_SSIM: 0.5793\n",
            "Epoch 15/30\n",
            "164/164 [==============================] - 941s 6s/step - loss: 0.0159 - PSNR: 66.4917 - SSIM: 0.5406 - val_loss: 0.0140 - val_PSNR: 66.9947 - val_SSIM: 0.5884\n",
            "Epoch 16/30\n",
            "164/164 [==============================] - 934s 6s/step - loss: 0.0157 - PSNR: 66.5192 - SSIM: 0.5420 - val_loss: 0.0139 - val_PSNR: 67.1147 - val_SSIM: 0.5852\n",
            "Epoch 17/30\n",
            "164/164 [==============================] - 927s 6s/step - loss: 0.0157 - PSNR: 66.5212 - SSIM: 0.5429 - val_loss: 0.0136 - val_PSNR: 67.2160 - val_SSIM: 0.5828\n",
            "Epoch 18/30\n",
            "164/164 [==============================] - 929s 6s/step - loss: 0.0155 - PSNR: 66.5862 - SSIM: 0.5447 - val_loss: 0.0136 - val_PSNR: 67.0985 - val_SSIM: 0.5895\n",
            "Epoch 19/30\n",
            "164/164 [==============================] - 932s 6s/step - loss: 0.0153 - PSNR: 66.6507 - SSIM: 0.5461 - val_loss: 0.0136 - val_PSNR: 67.1312 - val_SSIM: 0.5856\n",
            "Epoch 20/30\n",
            "164/164 [==============================] - 939s 6s/step - loss: 0.0152 - PSNR: 66.6497 - SSIM: 0.5478 - val_loss: 0.0135 - val_PSNR: 67.2363 - val_SSIM: 0.5827\n",
            "Epoch 21/30\n",
            "164/164 [==============================] - 930s 6s/step - loss: 0.0151 - PSNR: 66.6968 - SSIM: 0.5478 - val_loss: 0.0135 - val_PSNR: 67.1660 - val_SSIM: 0.5807\n",
            "Epoch 22/30\n",
            "164/164 [==============================] - 936s 6s/step - loss: 0.0150 - PSNR: 66.7071 - SSIM: 0.5489 - val_loss: 0.0130 - val_PSNR: 67.3246 - val_SSIM: 0.5898\n",
            "Epoch 23/30\n",
            "164/164 [==============================] - 956s 6s/step - loss: 0.0156 - PSNR: 66.5535 - SSIM: 0.5473 - val_loss: 0.0133 - val_PSNR: 67.1948 - val_SSIM: 0.5830\n",
            "Epoch 24/30\n",
            "164/164 [==============================] - 960s 6s/step - loss: 0.0151 - PSNR: 66.6962 - SSIM: 0.5496 - val_loss: 0.0128 - val_PSNR: 67.3604 - val_SSIM: 0.5872\n",
            "Epoch 25/30\n",
            "164/164 [==============================] - 955s 6s/step - loss: 0.0149 - PSNR: 66.7519 - SSIM: 0.5505 - val_loss: 0.0127 - val_PSNR: 67.4107 - val_SSIM: 0.5888\n",
            "Epoch 26/30\n",
            "164/164 [==============================] - 936s 6s/step - loss: 0.0146 - PSNR: 66.8315 - SSIM: 0.5530 - val_loss: 0.0130 - val_PSNR: 67.2784 - val_SSIM: 0.5870\n",
            "Epoch 27/30\n",
            "164/164 [==============================] - 940s 6s/step - loss: 0.0149 - PSNR: 66.7423 - SSIM: 0.5511 - val_loss: 0.0130 - val_PSNR: 67.2985 - val_SSIM: 0.5893\n",
            "Epoch 28/30\n",
            "164/164 [==============================] - 955s 6s/step - loss: 0.0146 - PSNR: 66.8481 - SSIM: 0.5533 - val_loss: 0.0127 - val_PSNR: 67.3657 - val_SSIM: 0.5876\n",
            "Epoch 29/30\n",
            "164/164 [==============================] - 951s 6s/step - loss: 0.0143 - PSNR: 66.8902 - SSIM: 0.5547 - val_loss: 0.0130 - val_PSNR: 67.2780 - val_SSIM: 0.5824\n",
            "Epoch 30/30\n",
            "164/164 [==============================] - 942s 6s/step - loss: 0.0142 - PSNR: 66.9318 - SSIM: 0.5556 - val_loss: 0.0125 - val_PSNR: 67.4548 - val_SSIM: 0.5892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N_mBIR_d8HK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}